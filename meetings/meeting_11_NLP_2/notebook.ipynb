{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 2 - Modele Sekwencyjne i ich zastosowania\n",
    "Modelem sekwencyjnym nazwiemy model, który jako wejście otrzymuje sekwencję, ale nie musi zwracać sekwencji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieci rekurencyjne\n",
    "Zasadą działania sieci rekurencyjnej jest przechowywanie wyjścia poprzedniego elementu i wykorzystania go w kolejnym kroku.\n",
    "\n",
    "Dlaczego po prostu do sekwencji nie wykorzystać zwykłych gęstych sieci neuronowych?\n",
    "* Nie są w stanie przetwarzać sekwencji o różnych długościach\n",
    "* Biorą pod uwagę tylko aktualne dane wejściowe\n",
    "* Nie zapamiętują informacji o poprzednich danych wejściowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele sekwencyjne można podzielić na kilka przykładów\n",
    "* One-to-many, wejście o długości jednostkowej, wyjście o długości > 1. Przykład: generacja tekstu\n",
    "   \n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-one-to-many-ltr.png?d246c2f0d1e0f43a21a8bd95f579cb3b)\n",
    "\n",
    "* Many-to-one, przykład klasyfikacja sentymentu\n",
    "\n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-many-to-one-ltr.png?c8a442b3ea9f4cb81f929c089b910c9d)\n",
    "\n",
    "* Many-to-many (tyle samo wejść co wyjść), przykład: NER(named entity recognition)\n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-many-to-many-same-ltr.png?2790431b32050b34b80011afead1f232)\n",
    "\n",
    "* Many-to-many, przykład tłumaczenie maszynowe\n",
    "\n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-many-to-many-different-ltr.png?8ca8bafd1eeac4e8c961d9293858407b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "Podstawową wersją sieci rekurencyjnej jest RNN(recurrent Neural Network)\n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/architecture-rnn-ltr.png?9ea4417fc145b9346a3e288801dbdfdc)\n",
    "\\begin{align*}\n",
    "    &a^{<t>}=g_1(W_{aa}a^{<t-1>}+W_{ax}x^{<t>}+b_a)\\\\\n",
    "    &y^{<t>}=g_2(W_{ya}a^{<t>}+b_y)\n",
    "\\end{align*}\n",
    "Gdzie $W_{ax},W_{aa},W_{ya},b_a,b_y$ to wagi naszej sieci, a $g_1,g_2$ to funkcje aktywacji.\n",
    "\n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/description-block-rnn-ltr.png?74e25518f882f8758439bcb3637715e5)\n",
    "\n",
    "W klasycznym RNN $y^{<t>}=a^{<t>}$.\n",
    "\n",
    "Zalety:\n",
    "* Możliwość przetwarzania sekwencji o dowolnej długości\n",
    "* Rozmiar modelu nie rośnie razem z długością sekwencji\n",
    "* Bierze pod uwagę poprzednie stany\n",
    "\n",
    "Wady:\n",
    "* Wolne obliczenia\n",
    "* Problem wykorzystywania bardzo odległych stanów\n",
    "* Nie może brać pod uwagę przyszłych stanów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksplodujący/Zanikający gradient\n",
    "Problem ten często spotyka się podczas korzystania z RNN. Wynika to z tego, że podczas wyliczania gradientu przemnażamy przez siebie wielokrotnie gradienty dla danych chwil czasowych w związku z tym może on zacząć zanikać(jak przemnażamy małe wartości), albo \"wybuchnąć\"(jak przemnażamy duże wartości).\n",
    "\n",
    "Jak sobie poradzić z tym problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "Aby poradzić sobie z problemem zależności od bardzo odległych wyjść wprowadzono LSTM.\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png)\n",
    "\n",
    "Gdzie $\\sigma$ to aktywacja sigmoid.\n",
    "\n",
    "Zatem jak można zauważyć LSTM posiada dwie \"ścieżki\" pamięci. Pierwszą jest tak zwany \"cell state\"\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png)\n",
    "Ze względu na to, że ma on tylko liniowe interakcje łatwo jest o przepływ informacji tą scieżką. LSTM ma możliwość usuwania i dodawania informacji do tej ścieżki, co jest decydowanie przez tak zwane bramki(gates). Decydują one o tym czy dana informacją powinna dalej przejść\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png)\n",
    "\n",
    "Ponieważ sigmoida zwraca wartości między 0 a 1 decyduje jak \"dużo\" informacji powinno przepłynąć dalej.\n",
    "\n",
    "#### LSTM krok po kroku\n",
    "W pierwszym kroku decydujemy jak wiele aktualnej informacji powinno zostać w cell state.\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png)\n",
    "\n",
    "Następnie decydujemy jak wiele nowej informacji powinniśmy dodać do cell state\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png)\n",
    "\n",
    "Dokonujemy aktualizacji cell state\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png)\n",
    "\n",
    "Na koniec wybieramy interesujące nas informacje z zakutalizowanego cell state, które zostaną zwrócone przez LSTM\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png)\n",
    "\n",
    "Istnieją jeszcze inne warianty LSTM np. wykorzystujące cell state do bramek\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-peepholes.png)\n",
    "\n",
    "i takie, które wykorzystują jedną bramkę do zapominania/dodawania informacji do cell state\n",
    "\n",
    "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-tied.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU a LSTM\n",
    "GRU jest kolejną siecią rekurencyjną, której celem jest rozwiązanie odległych relacji między momentami czasu\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*yBXV9o5q7L_CvY7quJt3WQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN\n",
    "Czasem może nas interesować nie tylko infromacja z lewej do prawej ale także w drugą stronę, np. podczas klasyfikacji tekstu, w związku z tym aby otrzymać Biderctional RNN łączymy wyniki z dwóch sieci RNN, jedna \"czyta\" od lewej do prawej, a druga w drugą stronę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = tf.ones((16, 25, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    recurrent_initializer=\"orthogonal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False,\n",
    ")\n",
    "rnn_layer(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    recurrent_initializer=\"orthogonal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False,\n",
    ")\n",
    "rnn_layer(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    recurrent_initializer=\"orthogonal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False,\n",
    ")\n",
    "output =  rnn_layer(example_input)\n",
    "print(type(output))\n",
    "print(output[0].shape, output[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Klasyfikacja tekstu przy użyciu RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "for example, label in train_dataset.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zadanie\n",
    "mając gotowe dane i tokenizer przetrenować sieć rekurencyjną do klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warstwe z embedingiem w tensorflow tworzymy następująco \n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True)\n",
    "# mask_zero powoduje, że wejścia które mają wartość 0 są pomijane w dalszych warstwach, tylko te warstwy muszą wspierwać maskowanie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aby stworzyć sieć RNN bidirectional wystarczy użyć\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    # tutaj wpisz swoje embeddingi i sieci RNN\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilacja modelu modelu\n",
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN a tekst\n",
    "\n",
    "Mając sekwencję możemy zamiast wykorzystywać RNN skorzystać z jednowymiarowej konwolucji. W tym przypadku rozmiar kernela(jądra) decyduje o tym na ile chwil czasowych jednocześnie patrzy CNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie\n",
    "korzystając z warstwy `tf.keras.layers.Conv1D` i jakiejś warstwy poolingowej zastąpić w poprzednim modelu RNN siecią CNN.\n",
    "Argumenty są takie same jak dla konwolucji 2D tylko `kernel_size` i `strides` mogą być tylko liczbami całkowitymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rozwiązanie\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Tutaj dodaj CNN\n",
    "        mask_zero=False),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextual embeddings\n",
    "Przy użyciu sieci rekurencyjnych można tworzyć embeddingi, które uwzględniają kontekst w jakim użyte jest dane słowo. Istnieje wiele słów, które jak są wykorzystane bez kontekstu nie można jednoznacznie określić ich znaczenia(np. zamek jako budowla i jako zapięcie kurtki). W związku z tym wykorzystuje się modele sekwencyjne, które modelują słowo w zależności od jego \"otoczenia\"\n",
    "##### ELMo\n",
    "Model ELMo wykorzsytuje sieci Bidirectional RNN do reprezentacji kontekstu\n",
    "\n",
    "![](https://jalammar.github.io/images/Bert-language-modeling.png)\n",
    "\n",
    "Działanie ELMo\n",
    "\n",
    "![](https://jalammar.github.io/images/elmo-forward-backward-language-model-embedding.png)\n",
    "\n",
    "![](https://jalammar.github.io/images/elmo-embedding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"ELMo lives on sesame street.\"]\n",
    "\n",
    "# Extract ELMo features \n",
    "embeddings = elmo(tf.constant(x))[\"elmo\"]\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "Modele Seq2Seq składają się z dwóch modeli sekwencyjnych, zazwyczaj pierwszy nazywa się `encoder` a drugi `decoder`. Zazwyczaj sekwencje wejściowe i wyjściowe mogą być różnej długości.\n",
    "Przykłady zastosowań\n",
    "* Machine translation\n",
    "* Table summarization\n",
    "* Image captioning\n",
    "* Document Summarization\n",
    "* Question Answering(np. chatboty)\n",
    "* Speech recognition\n",
    "\n",
    "![](https://blog.keras.io/img/seq2seq/seq2seq-teacher-forcing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanizm atencji\n",
    "\n",
    "W modelach Seq2Seq wykorzystuje się też często mechanizm atencji, który na podstawie stanu ukrytego ustala \"istotność\" danego wyjścia z encodera\n",
    "\n",
    "![](https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg)\n",
    "\n",
    "Istnieje wiele sposbów obliczania \"ważności\" danego wyjścia z encodera\n",
    "\n",
    "![](bahdanau_att.png)\n",
    "\n",
    "`Context vector` jest tworzony jako suma ważona na podstawie $a_t$, czyli $c_t=h_{enc}\\cdot a_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie\n",
    "Zaimplementuj w tensorflow encoder, decoder oraz mechanizm atencji.\n",
    "Encoder ma zwracać wszystkie stany ukryte oraz ostatni, który potem jest pierwszy stanem ukrytym w dekoderze. `Context vector` ma być konkatenowany z wyjściami z decodera.\n",
    "\n",
    "* W atencji można wykorzystać warstwę `tf.keras.layers.AdditiveAttention`, która ma następujące wejścia\n",
    "  * inputs: List of the following tensors:\n",
    "    * query: Query Tensor of shape [batch_size, Tq, dim].\n",
    "    * value: Value Tensor of shape [batch_size, Tv, dim].\n",
    "    * key: Optional key Tensor of shape [batch_size, Tv, dim]. If not given, will use value for both key and value, which is the most common case.\n",
    "  * mask: List of the following tensors:\n",
    "    * query_mask: A boolean mask Tensor of shape [batch_size, Tq]. If given, the output will be zero at the positions where mask==False.\n",
    "    * value_mask: A boolean mask Tensor of shape [batch_size, Tv]. If given, will apply the mask such that values at positions where mask==False do not contribute to the result.\n",
    "  * training: Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (no dropout).\n",
    "  * return_attention_scores: bool, it True, returns the attention scores (after masking and softmax) as an additional output argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        ...\n",
    "\n",
    "    def call(self, input_sequence):\n",
    "        ...\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        ...\n",
    "    \n",
    "    def call(self, encoder_output, decoder_hidden_states):\n",
    "        ...\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        ...\n",
    "\n",
    "    def call(self, hidden_states, context_vector):\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliografia\n",
    "#### Sieci rekurencyjne\n",
    "* [RNN i LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [ELMo-Embeddingi z kontekstem](https://arxiv.org/abs/1802.05365v2)\n",
    "* [BERT ELMo zilustrowane](https://jalammar.github.io/illustrated-bert/)\n",
    "* [Bahdanau Attention](https://arxiv.org/abs/1508.04025)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f60acc4feb66875ce3d3a7c45fd7be20da61778b03efde0a9ca4c6b3f9535b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bootcamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
